<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Language Modeling,ELMO,word representations," />










<meta name="description" content="NAACL 2018最佳论文 Deep contextualized word representations：艾伦人工智能研究所提出新型深度语境化词表征（研究者使用从双向 LSTM 中得到的向量，该 LSTM 是使用成对语言模型（LM）目标在大型文本语料库上训练得到的。因此，该表征叫作 ELMo（Embeddings from Language Models）表征。）。  ELMo 核心思想">
<meta name="keywords" content="Language Modeling,ELMO,word representations">
<meta property="og:type" content="article">
<meta property="og:title" content="ELMo Deep contextualized word representations">
<meta property="og:url" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/index.html">
<meta property="og:site_name" content="望江人工智库">
<meta property="og:description" content="NAACL 2018最佳论文 Deep contextualized word representations：艾伦人工智能研究所提出新型深度语境化词表征（研究者使用从双向 LSTM 中得到的向量，该 LSTM 是使用成对语言模型（LM）目标在大型文本语料库上训练得到的。因此，该表征叫作 ELMo（Embeddings from Language Models）表征。）。  ELMo 核心思想">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/e2.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/e1.jpg">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_01.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_02.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_03.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_04.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_05.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_06.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_07.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_08.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_09.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_10.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_11.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_12.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_13.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_14.png">
<meta property="og:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_15.png">
<meta property="og:updated_time" content="2019-04-17T06:24:42.716Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ELMo Deep contextualized word representations">
<meta name="twitter:description" content="NAACL 2018最佳论文 Deep contextualized word representations：艾伦人工智能研究所提出新型深度语境化词表征（研究者使用从双向 LSTM 中得到的向量，该 LSTM 是使用成对语言模型（LM）目标在大型文本语料库上训练得到的。因此，该表征叫作 ELMo（Embeddings from Language Models）表征。）。  ELMo 核心思想">
<meta name="twitter:image" content="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/e2.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/"/>





  <title>ELMo Deep contextualized word representations | 望江人工智库</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	<a href="https://github.com/yuanxiaosc" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">望江人工智库</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/29/ELMo_Deep_contextualized_word_representations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="望江车神">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://avatars0.githubusercontent.com/u/16183570?s=400&u=5e09ebb784cfd47de99d249f2be2413adcf4e672&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="望江人工智库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">ELMo Deep contextualized word representations</h1>
        

        <div class="post-meta">
		  

          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-29T09:55:50+08:00">
                2018-10-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文/" itemprop="url" rel="index">
                    <span itemprop="name">论文</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/29/ELMo_Deep_contextualized_word_representations/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/29/ELMo_Deep_contextualized_word_representations/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>NAACL 2018最佳论文 <a href="https://arxiv.org/abs/1802.05365v2" target="_blank" rel="noopener">Deep contextualized word representations</a>：艾伦人工智能研究所提出新型深度语境化词表征（研究者使用从双向 LSTM 中得到的向量，该 LSTM 是使用成对语言模型（LM）目标在大型文本语料库上训练得到的。因此，该表征叫作 ELMo（Embeddings from Language Models）表征。）。</p>
</blockquote>
<p><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/e2.png" alt=""><br>ELMo 核心思想</p>
<h2 id="最推荐-ELMo-TensorFlow-Hub-的使用方法"><a href="#最推荐-ELMo-TensorFlow-Hub-的使用方法" class="headerlink" title="最推荐 ELMo TensorFlow Hub 的使用方法"></a>最推荐 <a href="https://tfhub.dev/google/elmo/2" target="_blank" rel="noopener">ELMo TensorFlow Hub 的使用方法</a></h2><p><strong>Overview</strong><br>Computes contextualized word representations using character-based word representations and bidirectional LSTMs, as described in the paper “Deep contextualized word representations” [1].</p>
<p>This modules supports inputs both in the form of raw text strings or tokenized text strings.</p>
<p>The module outputs fixed embeddings at each LSTM layer, a learnable aggregation of the 3 layers, and a fixed mean-pooled vector representation of the input.</p>
<p>The complex architecture achieves state of the art results on several benchmarks. Note that this is a very computationally expensive module compared to word embedding modules that only perform embedding lookups. The use of an accelerator is recommended.</p>
<p>Trainable parameters<br>The module exposes 4 trainable scalar weights for layer aggregation.</p>
<p><strong>Example use</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">elmo = hub.Module(<span class="string">"https://tfhub.dev/google/elmo/2"</span>, trainable=<span class="keyword">True</span>)</span><br><span class="line">embeddings = elmo(</span><br><span class="line">[<span class="string">"the cat is on the mat"</span>, <span class="string">"dogs are in the fog"</span>],</span><br><span class="line">signature=<span class="string">"default"</span>,</span><br><span class="line">as_dict=<span class="keyword">True</span>)[<span class="string">"elmo"</span>]</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">elmo = hub.Module(<span class="string">"https://tfhub.dev/google/elmo/2"</span>, trainable=<span class="keyword">True</span>)</span><br><span class="line">tokens_input = [[<span class="string">"the"</span>, <span class="string">"cat"</span>, <span class="string">"is"</span>, <span class="string">"on"</span>, <span class="string">"the"</span>, <span class="string">"mat"</span>],</span><br><span class="line">[<span class="string">"dogs"</span>, <span class="string">"are"</span>, <span class="string">"in"</span>, <span class="string">"the"</span>, <span class="string">"fog"</span>, <span class="string">""</span>]]</span><br><span class="line">tokens_length = [<span class="number">6</span>, <span class="number">5</span>]</span><br><span class="line">embeddings = elmo(</span><br><span class="line">inputs=&#123;</span><br><span class="line"><span class="string">"tokens"</span>: tokens_input,</span><br><span class="line"><span class="string">"sequence_len"</span>: tokens_length</span><br><span class="line">&#125;,</span><br><span class="line">signature=<span class="string">"tokens"</span>,</span><br><span class="line">as_dict=<span class="keyword">True</span>)[<span class="string">"elmo"</span>]</span><br></pre></td></tr></table></figure>
<p><strong>Input</strong><br>The module defines two signatures: default, and tokens.</p>
<p>With the default signature, the module takes untokenized sentences as input. The input tensor is a string tensor with shape [batch_size]. The module tokenizes each string by splitting on spaces.</p>
<p>With the tokens signature, the module takes tokenized sentences as input. The input tensor is a string tensor with shape [batch_size, max_length] and an int32 tensor with shape [batch_size] corresponding to the sentence length. The length input is necessary to exclude padding in the case of sentences with varying length.</p>
<p><strong>Output</strong><br>The output dictionary contains:</p>
<ul>
<li>word_emb: the character-based word representations with shape [batch_size, max_length, 512].</li>
<li>lstm_outputs1: the first LSTM hidden state with shape [batch_size, max_length, 1024].</li>
<li>lstm_outputs2: the second LSTM hidden state with shape [batch_size, max_length, 1024].</li>
<li>elmo: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]</li>
<li>default: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024].</li>
</ul>
<h3 id="用代码来解释"><a href="#用代码来解释" class="headerlink" title="用代码来解释"></a>用代码来解释</h3><blockquote>
<p>更多内容见我的 <a href="https://github.com/yuanxiaosc/ELMo" target="_blank" rel="noopener">GitHub</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_hub <span class="keyword">as</span> hub</span><br><span class="line"><span class="comment"># elmo_url="https://tfhub.dev/google/elmo/2"</span></span><br><span class="line"><span class="comment"># hub.Module(elmo_url, trainable=True)</span></span><br><span class="line"><span class="comment"># You can either use the URL directly or download the file locally and then use it.</span></span><br><span class="line"><span class="comment"># hub.Module(path_to_elmo_model, trainable=True)</span></span><br><span class="line"></span><br><span class="line">tokens_input = [[<span class="string">"the"</span>, <span class="string">"cat"</span>, <span class="string">"is"</span>, <span class="string">"on"</span>, <span class="string">"the"</span>, <span class="string">"mat"</span>],</span><br><span class="line">                [<span class="string">"dogs"</span>, <span class="string">"are"</span>, <span class="string">"in"</span>, <span class="string">"the"</span>, <span class="string">"fog"</span>, <span class="string">""</span>]]</span><br><span class="line">tokens_length = [<span class="number">6</span>, <span class="number">5</span>]</span><br><span class="line">max_length = max(tokens_length)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokens_elmo</span><span class="params">(path_to_hub_elmo_model=<span class="string">"https://tfhub.dev/google/elmo/2"</span>)</span>:</span></span><br><span class="line">    elmo_tokens_input = tf.placeholder(dtype=tf.string, shape=[<span class="keyword">None</span>, max_length], name=<span class="string">"tokens_input"</span>)</span><br><span class="line">    elmo_sequence_length_input = tf.placeholder(dtype=tf.int32, shape=[<span class="keyword">None</span>,], name=<span class="string">"tokens_length"</span>)</span><br><span class="line"></span><br><span class="line">    module = hub.Module(path_to_hub_elmo_model, trainable=<span class="keyword">True</span>)</span><br><span class="line">    module_features = module(inputs=&#123;<span class="string">"tokens"</span>:elmo_tokens_input, <span class="string">"sequence_len"</span>:elmo_sequence_length_input&#125;,</span><br><span class="line">                             signature=<span class="string">'tokens'</span>, as_dict=<span class="keyword">True</span>)</span><br><span class="line">    elmo_embedding = module_features[<span class="string">"elmo"</span>]  <span class="comment">#[batch_size, max_length, 1024], the weighted sum of the 3 layers, where the weights are trainable.</span></span><br><span class="line">    <span class="keyword">return</span> elmo_tokens_input, elmo_sequence_length_input, elmo_embedding</span><br><span class="line"></span><br><span class="line">elmo_tokens_input, elmo_sequence_length_input, elmo_embedding = tokens_elmo(path_to_hub_elmo_model=<span class="string">"/home/b418/jupyter_workspace/B418_common/袁宵/tfhub_modules/elmo"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])</span><br><span class="line">    out_elmo_embedding = sess.run(elmo_embedding,feed_dict=&#123;elmo_tokens_input:tokens_input,</span><br><span class="line">                                                                elmo_sequence_length_input:tokens_length&#125;)</span><br><span class="line">    print(<span class="string">"out_elmo_shape:\t"</span>, out_elmo_embedding.shape)</span><br></pre></td></tr></table></figure>
<h2 id="广义-ELMo-使用方法"><a href="#广义-ELMo-使用方法" class="headerlink" title="广义 ELMo 使用方法"></a>广义 ELMo 使用方法</h2><p><a href="https://zhuanlan.zhihu.com/p/38254332" target="_blank" rel="noopener">如何使用ELMo的词向量呢？</a>( 论文 3.3 有详细描述)<br>在supervised learning的情况下，可以各种自如的使用:</p>
<ol>
<li>直接将ELMo词向量 ELMo_k 与普通的词向量 x_k拼接（concat）[ x_k;ELMo_k ]。</li>
<li>直接将ELMo词向量ELMo_k 与隐层输出向量 h_k 拼接[ h_k;ELMo_k ]，在SNLI,SQuAD上都有提升。</li>
</ol>
<p>代码使用实例：</p>
<ul>
<li><a href="https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md" target="_blank" rel="noopener">官方版</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/37915351" target="_blank" rel="noopener">知乎简版</a></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>标题</th>
<th>说明</th>
<th>附加</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://arxiv.org/abs/1802.05365v2" target="_blank" rel="noopener">Deep contextualized word representations</a></td>
<td>该研究提出了一种新型深度语境化词表征，可对词使用的复杂特征（如句法和语义）和词使用在语言语境中的变化进行建模（即对多义词进行建模）。这些表征可以轻松添加至已有模型，并在 6 个 NLP 问题中显著提高当前最优性能。</td>
<td>20180215</td>
</tr>
<tr>
<td><a href="https://tfhub.dev/google/elmo/2" target="_blank" rel="noopener">TensorFlow Hub 实现</a></td>
<td>Embeddings from a language model trained on the 1 Billion Word Benchmark.</td>
<td></td>
</tr>
<tr>
<td><a href="https://allennlp.org/elmo" target="_blank" rel="noopener">allennlp.org - elmo</a></td>
<td>论文官网 elmo</td>
<td></td>
</tr>
<tr>
<td><a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">bilm-tf</a></td>
<td>论文官方实现 Tensorflow implementation of contextualized word representations from bi-directional language models</td>
<td></td>
</tr>
<tr>
<td><a href="https://www.jiqizhixin.com/articles/060704" target="_blank" rel="noopener">NAACL 2018最佳论文：艾伦人工智能研究所提出新型深度语境化词表征</a></td>
<td>机器之心解读</td>
<td>20180607</td>
</tr>
<tr>
<td><a href="https://github.com/strongio/keras-elmo" target="_blank" rel="noopener">把 ELMo 作为 keras 的一个嵌入层使用</a></td>
<td>GitHub</td>
<td>201804</td>
</tr>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/36221795" target="_blank" rel="noopener">NAACL18 Best Paper: ELMo</a></td>
<td><a href="https://www.zhihu.com/people/liyuan-liu-64" target="_blank" rel="noopener">Liyuan Liu</a> 解读</td>
<td></td>
</tr>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/37684922" target="_blank" rel="noopener">论文笔记ELMo</a></td>
<td><a href="https://www.zhihu.com/people/zhao-lai-fu-72/activities" target="_blank" rel="noopener">赵来福</a> 详细解读</td>
<td></td>
</tr>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/38254332" target="_blank" rel="noopener">ELMo 最好用的词向量《Deep Contextualized Word Representations》</a></td>
<td><a href="https://www.zhihu.com/people/mountain-blue-64/activities" target="_blank" rel="noopener">mountain blue</a> 详细解读</td>
<td></td>
</tr>
<tr>
<td><a href="https://towardsdatascience.com/visualizing-elmo-contextual-vectors-94168768fdaa" target="_blank" rel="noopener">visualizing-elmo-contextual-vectors</a></td>
<td>可视化ELMo上下文向量</td>
<td>20190417</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/e1.jpg" alt=""></p>
<h1 id="Deep-contextualized-word-representations"><a href="#Deep-contextualized-word-representations" class="headerlink" title="Deep contextualized word representations"></a><a href="https://arxiv.org/abs/1802.05365v2" target="_blank" rel="noopener">Deep contextualized word representations</a></h1><p>Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer</p>
<blockquote>
<p>Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.</p>
<p>在本论文中，我们介绍了一种新型深度语境化词表征，可对词使用的复杂特征（如句法和语义）和词使用在语言语境中的变化进行建模（即对多义词进行建模）。我们的词向量是深度双向语言模型（biLM）内部状态的函数，在一个大型文本语料库中预训练而成。本研究表明，这些表征能够被轻易地添加到现有的模型中，并在六个颇具挑战性的 NLP 问题（包括问答、文本蕴涵和情感分析）中显著提高当前最优性能。此外，我们的分析还表明，揭示预训练网络的深层内部状态至关重要，可以允许下游模型综合不同类型的半监督信号。</p>
</blockquote>
<p>Comments:    NAACL 2018. Originally posted to openreview 27 Oct 2017. v2 updated for NAACL camera ready<br>Subjects:    Computation and Language (cs.CL)<br>Cite as:    arXiv:1802.05365 [cs.CL]<br>     (or arXiv:1802.05365v2 [cs.CL] for this version)</p>
<p><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_01.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_02.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_03.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_04.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_05.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_06.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_07.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_08.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_09.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_10.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_11.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_12.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_13.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_14.png" alt=""><br><img src="/2018/10/29/ELMo_Deep_contextualized_word_representations/ELMo_paper_页面_15.png" alt=""></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>感谢金主！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="望江车神 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="望江车神 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Language-Modeling/" rel="tag"># Language Modeling</a>
          
            <a href="/tags/ELMO/" rel="tag"># ELMO</a>
          
            <a href="/tags/word-representations/" rel="tag"># word representations</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/10/29/ELMo_Deep_contextualized_word_representations翻译/" rel="next" title="ELMo Deep contextualized word representations翻译">
                <i class="fa fa-chevron-left"></i> ELMo Deep contextualized word representations翻译
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/10/29/Character_Aware_Neural_Language_Models/" rel="prev" title="Character-Aware Neural Language Models">
                Character-Aware Neural Language Models <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://avatars0.githubusercontent.com/u/16183570?s=400&u=5e09ebb784cfd47de99d249f2be2413adcf4e672&v=4"
                alt="望江车神" />
            
              <p class="site-author-name" itemprop="name">望江车神</p>
              <p class="site-description motion-element" itemprop="description">深度学习你~~~</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">141</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">57</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">126</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yuanxiaoSC" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:wangzichaochaochao@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#最推荐-ELMo-TensorFlow-Hub-的使用方法"><span class="nav-number">1.</span> <span class="nav-text">最推荐 ELMo TensorFlow Hub 的使用方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#用代码来解释"><span class="nav-number">1.1.</span> <span class="nav-text">用代码来解释</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#广义-ELMo-使用方法"><span class="nav-number">2.</span> <span class="nav-text">广义 ELMo 使用方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-contextualized-word-representations"><span class="nav-number"></span> <span class="nav-text">Deep contextualized word representations</span></a></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">望江车神</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'aTXvwHFSoz68yg6g3k5JzN7B-MdYXbMMI',
        appKey: 'Wkf7bKVEfcQ0sW4V1l144HLY',
        placeholder: '欢迎交流',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
