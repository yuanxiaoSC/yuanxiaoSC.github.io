{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow自动求导和梯度下降原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文以华氏温度转换为摄氏温度（一元线性回归模型）为例子，讲解了深度学习框架（TensorFlow）自动求导和梯度下降的原理。文章内容分为三节，层层递进，分别是：\n",
    "1. 手动反向传播求导、手动梯度下降\n",
    "2. 自动求导，手动梯度下降\n",
    "3. 自动求导，自动梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据\n",
    "Y = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] # 摄氏度 Celsius\n",
    "X = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # 华氏度 Fahrenheit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(11,), dtype=float32, numpy=\n",
       " array([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4],\n",
       "       dtype=float32)>, <tf.Tensor: shape=(11,), dtype=float32, numpy=\n",
       " array([ 0.5, 14. , 15. , 28. , 11. ,  8. ,  3. , -4. ,  6. , 13. , 21. ],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化成张量\n",
    "Y = tf.constant(Y)\n",
    "X = tf.constant(X)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型与损失函数。这里使用最简单的一元线性回归模型和均方根损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, w, b):\n",
    "    return w * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(Y_hat, Y):\n",
    "    squared_diffs = (Y_hat - Y)**2\n",
    "    return tf.reduce_mean(squared_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动反向传播求导、手动梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型参数\n",
    "w = tf.ones(1)\n",
    "b = tf.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=float32, numpy=\n",
       "array([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型预测输出\n",
    "Y_hat = model(X, w, b)\n",
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1763.8848>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型损失\n",
    "loss = loss_fn(Y_hat, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手动反向传播求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(Y_hat, Y):\n",
    "    dsq_diffs = 2 * (Y_hat - Y)\n",
    "    return dsq_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dw(X, w, b):\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_db(X, w, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(X, Y, Y_hat, w, b):\n",
    "    dloss_dw = dloss_fn(Y_hat, Y) * dmodel_dw(X, w, b)\n",
    "    dloss_db = dloss_fn(Y_hat, Y) * dmodel_db(X, w, b)\n",
    "    return tf.stack([tf.reduce_mean(dloss_dw), tf.reduce_mean(dloss_db)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, X, Y, print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "\n",
    "        Y_hat = model(X, w, b)  # <1>\n",
    "        loss = loss_fn(Y_hat, Y)\n",
    "        grad = grad_fn(X, Y, Y_hat, w, b)  # <2>\n",
    "\n",
    "        params = params - learning_rate * grad # 手动梯度下降\n",
    "\n",
    "        if epoch % 30000 == 0:  # <3>\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            if print_params:\n",
    "                print('    Params:', params)\n",
    "                print('    Grad:  ', grad)\n",
    "\n",
    "        if tf.math.is_inf(loss):\n",
    "            break  # <3>\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30000, Loss 12.095908\n",
      "Epoch 60000, Loss 6.133891\n",
      "Epoch 90000, Loss 4.048903\n",
      "Epoch 120000, Loss 3.319792\n",
      "Epoch 150000, Loss 3.064586\n",
      "Epoch 180000, Loss 2.975681\n",
      "Epoch 210000, Loss 2.944574\n",
      "Epoch 240000, Loss 2.933552\n",
      "Epoch 270000, Loss 2.929731\n",
      "Epoch 300000, Loss 2.928472\n",
      "Epoch 330000, Loss 2.927906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([  0.5358124, -17.250313 ], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = training_loop(\n",
    "    n_epochs = 330000, \n",
    "    learning_rate = 1e-4, \n",
    "    params = tf.constant([1.00, 0.01]), \n",
    "    X = X, \n",
    "    Y = Y,\n",
    "    print_params = False)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测。根据训练后的参数进行模型预测。\n",
    "Y_hat = model(X, *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc38cc7dfd0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 比较预测结果（直线）与标准答案（圆点）\n",
    "fig = plt.figure()\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.plot(X.numpy(), Y_hat.numpy()) # <2>\n",
    "plt.plot(X.numpy(), Y.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求导，手动梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型参数\n",
    "params = tf.constant([1.00, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型损失函数\n",
    "loss_object = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(params) # 指定要求导的对象\n",
    "    Y_hat = model(X, *params)\n",
    "    loss = loss_object(Y_hat, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动反向传播求导\n",
    "gradients = tape.gradient(loss, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4518.333,   82.62 ], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看导数值\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, X, Y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(params)\n",
    "            Y_hat = model(X, *params)\n",
    "            loss = loss_object(Y_hat, Y) \n",
    "        gradients = tape.gradient(loss, params)\n",
    "        params = params - learning_rate * gradients\n",
    "        if epoch % 30000 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30000, Loss 12.095908\n",
      "Epoch 60000, Loss 6.133891\n",
      "Epoch 90000, Loss 4.048903\n",
      "Epoch 120000, Loss 3.319792\n",
      "Epoch 150000, Loss 3.064586\n",
      "Epoch 180000, Loss 2.975681\n",
      "Epoch 210000, Loss 2.944574\n",
      "Epoch 240000, Loss 2.933552\n",
      "Epoch 270000, Loss 2.929731\n",
      "Epoch 300000, Loss 2.928472\n",
      "Epoch 330000, Loss 2.927906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([  0.5358124, -17.250313 ], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 330000, \n",
    "    learning_rate = 1e-4, \n",
    "    params = tf.constant([1.00, 0.01]),\n",
    "    X = X,\n",
    "    Y = Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求导，自动梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, params):\n",
    "    return params[0] * X + params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(Y_hat, Y):\n",
    "    squared_diffs = (Y_hat - Y)**2\n",
    "    return tf.reduce_mean(squared_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型参数、损失函数、优化器\n",
    "params = tf.Variable([1.00, 0.01])\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(params)\n",
    "    Y_hat = model(X, params)\n",
    "    loss = loss_object(Y_hat, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动反向传播求导\n",
    "gradients = tape.gradient(loss, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4518.333,   82.62 ], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看导数值\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1.  , 0.01], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看参数值\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动梯度下降\n",
    "optimizer.apply_gradients(zip([gradients], [params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0.54816675, 0.001738  ], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看自动梯度下降后的参数值\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, params, X, Y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(params)\n",
    "            Y_hat = model(X, params)\n",
    "            loss = loss_object(Y_hat, Y) \n",
    "        gradients = tape.gradient(loss, params)\n",
    "        optimizer.apply_gradients(zip([gradients], [params]))\n",
    "        if epoch % 30000 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30000, Loss 12.095908\n",
      "Epoch 60000, Loss 6.133891\n",
      "Epoch 90000, Loss 4.048903\n",
      "Epoch 120000, Loss 3.319792\n",
      "Epoch 150000, Loss 3.064586\n",
      "Epoch 180000, Loss 2.975681\n",
      "Epoch 210000, Loss 2.944574\n",
      "Epoch 240000, Loss 2.933552\n",
      "Epoch 270000, Loss 2.929731\n",
      "Epoch 300000, Loss 2.928472\n",
      "Epoch 330000, Loss 2.927906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([  0.5358124, -17.250313 ], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 330000, \n",
    "    params = tf.Variable([1.00, 0.01]),\n",
    "    X = X,\n",
    "    Y = Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
