<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.7.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon-32x32.ico?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="baidu-site-verification" content="eYmWT0dEmt">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":true,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="Attention是一种用于提升基于RNN（LSTM或GRU）的Encoder + Decoder模型的效果的的机制（Mechanism），一般称为Attention Mechanism。Attention Mechanism目前非常流行，广泛应用于机器翻译、语音识别、图像标注（Image Caption）等很多领域，之所以它这么受欢迎，是因为Attention给模型赋予了区分辨别的能力，例如，在">
<meta name="keywords" content="注意力机制,Attention Mechanism">
<meta property="og:type" content="article">
<meta property="og:title" content="注意力机制">
<meta property="og:url" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/index.html">
<meta property="og:site_name" content="望江人工智库">
<meta property="og:description" content="Attention是一种用于提升基于RNN（LSTM或GRU）的Encoder + Decoder模型的效果的的机制（Mechanism），一般称为Attention Mechanism。Attention Mechanism目前非常流行，广泛应用于机器翻译、语音识别、图像标注（Image Caption）等很多领域，之所以它这么受欢迎，是因为Attention给模型赋予了区分辨别的能力，例如，在">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/b1.jpg">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/b2.jpg">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/c3.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/c2.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/attention.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/attention_code.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/e1.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/a1.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/a2.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/d1.jpg">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/a3.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/a4.png">
<meta property="og:updated_time" content="2019-02-28T03:05:30.580Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="注意力机制">
<meta name="twitter:description" content="Attention是一种用于提升基于RNN（LSTM或GRU）的Encoder + Decoder模型的效果的的机制（Mechanism），一般称为Attention Mechanism。Attention Mechanism目前非常流行，广泛应用于机器翻译、语音识别、图像标注（Image Caption）等很多领域，之所以它这么受欢迎，是因为Attention给模型赋予了区分辨别的能力，例如，在">
<meta name="twitter:image" content="https://yuanxiaosc.github.io/2019/02/28/注意力机制/b1.jpg">
  <link rel="canonical" href="https://yuanxiaosc.github.io/2019/02/28/注意力机制/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>注意力机制 | 望江人工智库</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?359fbde2215e8ede98cdd58478ab2c53";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">望江人工智库</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">TF-KMP</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="fa fa-search fa-fw"></i>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/yuanxiaosc" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yuanxiaosc.github.io/2019/02/28/注意力机制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="袁宵">
      <meta itemprop="description" content="专注于机器学习前沿论文（技术）研究和应用，欢迎邮件交流。">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="望江人工智库">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">注意力机制

          
        </h2>

        <div class="post-meta">
		  	  
			  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
			   

              
                
              

              <time title="创建时间：2019-02-28 16:12:10 / 修改时间：11:05:30" itemprop="dateCreated datePublished" datetime="2019-02-28T16:12:10+08:00">2019-02-28</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Attention是一种用于提升基于RNN（LSTM或GRU）的Encoder + Decoder模型的效果的的机制（Mechanism），一般称为Attention Mechanism。Attention Mechanism目前非常流行，广泛应用于机器翻译、语音识别、图像标注（Image Caption）等很多领域，之所以它这么受欢迎，是因为Attention给模型赋予了区分辨别的能力，例如，在机器翻译、语音识别应用中，为句子中的每个词赋予不同的权重，使神经网络模型的学习变得更加灵活（soft），同时Attention本身可以做为一种对齐关系，解释翻译输入/输出句子之间的对齐关系，解释模型到底学到了什么知识，为我们打开深度学习的黑箱，提供了一个窗口。</p><a id="more"></a>
<p><strong>注意，随着研究的深入，注意力的概念已经发生了变化，上述内容只是注意力中的一种而已。</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>标题</th>
<th>说明</th>
<th>时间</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://zhuanlan.zhihu.com/p/31547842" target="_blank" rel="noopener">模型汇总24 - 深度学习中Attention Mechanism详细介绍：原理、分类及应用</a></td>
<td>首推 知乎</td>
<td>2017</td>
</tr>
<tr>
<td><a href="https://www.zhihu.com/question/68482809/answer/264632289" target="_blank" rel="noopener">目前主流的attention方法都有哪些？</a></td>
<td>attention机制详解 知乎</td>
<td>2017</td>
</tr>
<tr>
<td><a href="https://github.com/tensorflow/nmt" target="_blank" rel="noopener">Neural Machine Translation (seq2seq) Tutorial</a></td>
<td>GitHub 以机器翻译为例讲解注意力机制</td>
<td>长期更新</td>
</tr>
<tr>
<td><a href="https://www.jianshu.com/p/c6b4c7810ee6" target="_blank" rel="noopener">Attention_Network_With_Keras 注意力模型的代码的实现与分析</a></td>
<td>代码解析 简书</td>
<td>20180617</td>
</tr>
<tr>
<td><a href="https://github.com/Choco31415/Attention_Network_With_Keras" target="_blank" rel="noopener">Attention_Network_With_Keras</a></td>
<td>代码实现 GitHub</td>
<td>2018</td>
</tr>
<tr>
<td><a href="https://www.jiqizhixin.com/articles/2018-10-08-12" target="_blank" rel="noopener">各种注意力机制窥探深度学习在NLP中的神威</a></td>
<td>综述 机器之心</td>
<td>20181008</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1808.08946.pdf" target="_blank" rel="noopener">Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures</a></td>
<td><a href="https://www.jiqizhixin.com/articles/2018-09-17-5" target="_blank" rel="noopener">为什么使用自注意力机制？</a> 实验结果证明：1）自注意力网络和 CNN 在建模长距离主谓一致时性能并不优于 RNN；2）自注意力网络在词义消歧方面显著优于 RNN 和 CNN。</td>
<td>20180827</td>
</tr>
<tr>
<td><a href="https://plmsmile.github.io/2018/03/25/33-attention-summary/" target="_blank" rel="noopener">各种注意力总结</a></td>
<td>本文主要是总结：注意力机制、注意力机制的变体、论文中常见的注意力</td>
<td>20180325</td>
</tr>
</tbody>
</table>
</div>
<h1 id="以2014《Learning-Phrase-Representations-using-RNN-Encoder-Decoder-for-Statistical-Machine-Translation》抛砖引玉"><a href="#以2014《Learning-Phrase-Representations-using-RNN-Encoder-Decoder-for-Statistical-Machine-Translation》抛砖引玉" class="headerlink" title="以2014《Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation》抛砖引玉"></a>以<a href="https://arxiv.org/abs/1406.1078" target="_blank" rel="noopener">2014《Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation》</a>抛砖引玉</h1><p>要介绍Attention Mechanism结构和原理，首先需要介绍下Seq2Seq模型的结构。基于RNN的Seq2Seq模型主要由两篇论文介绍，只是采用了不同的RNN模型。Ilya Sutskever等人与2014年在论文<a href="http://cn.arxiv.org/abs/1409.3215" target="_blank" rel="noopener">《Sequence to Sequence Learning with Neural Networks》</a>中使用LSTM来搭建Seq2Seq模型。随后，2015年，Kyunghyun Cho等人在论文《Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation》提出了基于GRU的Seq2Seq模型。两篇文章所提出的Seq2Seq模型，想要解决的主要问题是，如何把机器翻译中，变长的输入X映射到一个变长输出Y的问题，其主要结构如图所示。</p>
<p><img src="/2019/02/28/注意力机制/b1.jpg" alt=""><br><strong>传统的Seq2Seq结构</strong></p>
<p>其中，Encoder把一个变成的输入序列x1，x2，x3….xt编码成一个固定长度隐向量（背景向量，或上下文向量context）c，c有两个作用：1、做为初始向量初始化Decoder的模型，做为decoder模型预测y1的初始向量。2、做为背景向量，指导y序列中每一个step的y的产出。Decoder主要基于背景向量c和上一步的输出yt-1解码得到该时刻t的输出yt，直到碰到结束标志（$<eos>$）为止。</eos></p>
<p>如上文所述，传统的Seq2Seq模型对输入序列X缺乏区分度，因此，2015年，Kyunghyun Cho等人在论文《Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation》中，引入了Attention Mechanism来解决这个问题，他们提出的模型结构如图所示。</p>
<p><img src="/2019/02/28/注意力机制/b2.jpg" alt=""><br><strong>Attention Mechanism模块图解</strong></p>
<p><img src="/2019/02/28/注意力机制/c3.png" alt=""><br><img src="/2019/02/28/注意力机制/c2.png" alt=""></p>
<h1 id="以Attention-Network-With-Keras-为例讲解一种Attention实现代码"><a href="#以Attention-Network-With-Keras-为例讲解一种Attention实现代码" class="headerlink" title="以Attention_Network_With_Keras 为例讲解一种Attention实现代码"></a>以<a href="https://github.com/Choco31415/Attention_Network_With_Keras" target="_blank" rel="noopener">Attention_Network_With_Keras</a> 为例讲解一种Attention实现代码</h1><h2 id="部分代码"><a href="#部分代码" class="headerlink" title="部分代码"></a>部分代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Tx = <span class="number">50</span> <span class="comment"># Max x sequence length</span></span><br><span class="line">Ty = <span class="number">5</span> <span class="comment"># y sequence length</span></span><br><span class="line">X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split data 80-20 between training and test</span></span><br><span class="line">train_size = int(<span class="number">0.8</span>*m)</span><br><span class="line">Xoh_train = Xoh[:train_size]</span><br><span class="line">Yoh_train = Yoh[:train_size]</span><br><span class="line">Xoh_test = Xoh[train_size:]</span><br><span class="line">Yoh_test = Yoh[train_size:]</span><br></pre></td></tr></table></figure>
<p>To be careful, let’s check that the code works:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">5</span></span><br><span class="line">print(<span class="string">"Input data point "</span> + str(i) + <span class="string">"."</span>)</span><br><span class="line">print(<span class="string">""</span>)</span><br><span class="line">print(<span class="string">"The data input is: "</span> + str(dataset[i][<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"The data output is: "</span> + str(dataset[i][<span class="number">1</span>]))</span><br><span class="line">print(<span class="string">""</span>)</span><br><span class="line">print(<span class="string">"The tokenized input is:"</span> + str(X[i]))</span><br><span class="line">print(<span class="string">"The tokenized output is: "</span> + str(Y[i]))</span><br><span class="line">print(<span class="string">""</span>)</span><br><span class="line">print(<span class="string">"The one-hot input is:"</span>, Xoh[i])</span><br><span class="line">print(<span class="string">"The one-hot output is:"</span>, Yoh[i])</span><br></pre></td></tr></table></figure>
<pre><code>Input data point 5.

The data input is: 23 min after 20 p.m.
The data output is: 20:23

The tokenized input is:[ 5  6  0 25 22 26  0 14 19 32 18 30  0  5  3  0 28  2 25  2 40 40 40 40
 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
 40 40]
The tokenized output is: [ 2  0 10  2  3]

The one-hot input is: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [1. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 0. 0. 1.]]
The one-hot output is: [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
</code></pre><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Our next goal is to define our model. The important part will be defining the attention mechanism and then making sure to apply that correctly.</p>
<p>Define some model metadata:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">layer1_size = <span class="number">32</span></span><br><span class="line">layer2_size = <span class="number">128</span> <span class="comment"># Attention layer</span></span><br></pre></td></tr></table></figure>
<p>The next two code snippets defined the attention mechanism. This is split into two arcs:</p>
<ul>
<li>Calculating context</li>
<li>Creating an attention layer</li>
</ul>
<p>As a refresher, an attention network pays attention to certain parts of the input at each output time step. _attention_ denotes which inputs are most relevant to the current output step. An input step will have attention weight ~1 if it is relevant, and ~0 otherwise. The _context_ is the “summary of the input”.</p>
<p>The requirements are thus. The attention matrix should have shape $(T_x)$ and sum to 1. Additionally, the context should be calculated in the same manner for each time step. Beyond that, there is some flexibility. This notebook calculates both this way:</p>
<script type="math/tex; mode=display">
attention = Softmax(Dense(Dense(x, y_{t-1})))</script><p><br></p>
<script type="math/tex; mode=display">
context = \sum_{i=1}^{m} ( attention_i * x_i )</script><p>For safety, $y_0$ is defined as $\vec{0}$.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define part of the attention layer gloablly so as to</span></span><br><span class="line"><span class="comment"># share the same layers for each attention step.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> K.softmax(x, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">at_repeat = RepeatVector(Tx)</span><br><span class="line">at_concatenate = Concatenate(axis=<span class="number">-1</span>)</span><br><span class="line">at_dense1 = Dense(<span class="number">8</span>, activation=<span class="string">"tanh"</span>)</span><br><span class="line">at_dense2 = Dense(<span class="number">1</span>, activation=<span class="string">"relu"</span>)</span><br><span class="line">at_softmax = Activation(softmax, name=<span class="string">'attention_weights'</span>)</span><br><span class="line">at_dot = Dot(axes=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_step_of_attention</span><span class="params">(h_prev, a)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Get the context.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    h_prev - Previous hidden state of a RNN layer (m, n_h)</span></span><br><span class="line"><span class="string">    a - Input data, possibly processed (m, Tx, n_a)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    context - Current context (m, Tx, n_a)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Repeat vector to match a's dimensions</span></span><br><span class="line">    h_repeat = at_repeat(h_prev)</span><br><span class="line">    <span class="comment"># Calculate attention weights</span></span><br><span class="line">    i = at_concatenate([a, h_repeat])</span><br><span class="line">    i = at_dense1(i)</span><br><span class="line">    i = at_dense2(i)</span><br><span class="line">    attention = at_softmax(i)</span><br><span class="line">    <span class="comment"># Calculate the context</span></span><br><span class="line">    context = at_dot([attention, a])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_layer</span><span class="params">(X, n_h, Ty)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates an attention layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    X - Layer input (m, Tx, x_vocab_size)</span></span><br><span class="line"><span class="string">    n_h - Size of LSTM hidden layer</span></span><br><span class="line"><span class="string">    Ty - Timesteps in output sequence</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    output - The output of the attention layer (m, Tx, n_h)</span></span><br><span class="line"><span class="string">    """</span>    </span><br><span class="line">    <span class="comment"># Define the default state for the LSTM layer</span></span><br><span class="line">    h = Lambda(<span class="keyword">lambda</span> X: K.zeros(shape=(K.shape(X)[<span class="number">0</span>], n_h)), name=<span class="string">'h_attention_layer'</span>)(X)</span><br><span class="line">    c = Lambda(<span class="keyword">lambda</span> X: K.zeros(shape=(K.shape(X)[<span class="number">0</span>], n_h)), name=<span class="string">'c_attention_layer'</span>)(X)</span><br><span class="line">    <span class="comment"># Messy, but the alternative is using more Input()</span></span><br><span class="line"></span><br><span class="line">    at_LSTM = LSTM(n_h, return_state=<span class="keyword">True</span>, name=<span class="string">'at_LSTM_attention_layer'</span>)</span><br><span class="line"></span><br><span class="line">    output = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run attention step and RNN for each output time step</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(Ty):</span><br><span class="line">        context = one_step_of_attention(h, X)</span><br><span class="line"></span><br><span class="line">        h, _, c = at_LSTM(context, initial_state=[h, c])</span><br><span class="line"></span><br><span class="line">        output.append(h)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>The sample model is organized as follows:</p>
<ol>
<li>BiLSTM</li>
<li>Attention Layer<ul>
<li>Outputs Ty lists of activations.</li>
</ul>
</li>
<li>Dense<ul>
<li>Necessary to convert attention layer’s output to the correct y dimensions</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">layer3 = Dense(machine_vocab_size, activation=softmax)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(Tx, Ty, layer1_size, layer2_size, x_vocab_size, y_vocab_size)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates a model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">    Tx - Number of x timesteps</span></span><br><span class="line"><span class="string">    Ty - Number of y timesteps</span></span><br><span class="line"><span class="string">    size_layer1 - Number of neurons in BiLSTM</span></span><br><span class="line"><span class="string">    size_layer2 - Number of neurons in attention LSTM hidden layer</span></span><br><span class="line"><span class="string">    x_vocab_size - Number of possible token types for x</span></span><br><span class="line"><span class="string">    y_vocab_size - Number of possible token types for y</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    model - A Keras Model.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create layers one by one</span></span><br><span class="line">    X = Input(shape=(Tx, x_vocab_size), name=<span class="string">'X_Input'</span>)</span><br><span class="line"></span><br><span class="line">    a1 = Bidirectional(LSTM(layer1_size, return_sequences=<span class="keyword">True</span>), merge_mode=<span class="string">'concat'</span>, name=<span class="string">'Bid_LSTM'</span>)(X)</span><br><span class="line"></span><br><span class="line">    a2 = attention_layer(a1, layer2_size, Ty)</span><br><span class="line"></span><br><span class="line">    a3 = [layer3(timestep) <span class="keyword">for</span> timestep <span class="keyword">in</span> a2]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create Keras model</span></span><br><span class="line">    model = Model(inputs=[X], outputs=a3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>The steps from here on out are for creating the model and training it. Simple as that.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Obtain a model instance</span></span><br><span class="line">model = get_model(Tx, Ty, layer1_size, layer2_size, human_vocab_size, machine_vocab_size)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_model(model, to_file=<span class="string">'Attention_tutorial_model_copy.png'</span>, show_shapes=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型结构及说明"><a href="#模型结构及说明" class="headerlink" title="模型结构及说明"></a>模型结构及说明</h2><p><img src="/2019/02/28/注意力机制/attention.png" alt=""></p>
<p><img src="/2019/02/28/注意力机制/attention_code.png" alt=""></p>
<h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>The final training loss should be in the range of 0.02 to 0.5</p>
<p>The test loss should be at a similar level.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate the test performance</span></span><br><span class="line">outputs_test = list(Yoh_test.swapaxes(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">score = model.evaluate(Xoh_test, outputs_test)</span><br><span class="line">print(<span class="string">'Test loss: '</span>, score[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>2000/2000 [==============================] - 2s 1ms/step
Test loss:  0.4966005325317383
</code></pre><p>Now that we’ve created this beautiful model, let’s see how it does in action.</p>
<p>The below code finds a random example and runs it through our model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let's visually check model output.</span></span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> random</span><br><span class="line"></span><br><span class="line">i = random.randint(<span class="number">0</span>, m)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_prediction</span><span class="params">(model, x)</span>:</span></span><br><span class="line">    prediction = model.predict(x)</span><br><span class="line">    max_prediction = [y.argmax() <span class="keyword">for</span> y <span class="keyword">in</span> prediction]</span><br><span class="line">    str_prediction = <span class="string">""</span>.join(ids_to_keys(max_prediction, machine_vocab))</span><br><span class="line">    <span class="keyword">return</span> (max_prediction, str_prediction)</span><br><span class="line"></span><br><span class="line">max_prediction, str_prediction = get_prediction(model, Xoh[i:i+<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Input: "</span> + str(dataset[i][<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"Tokenized: "</span> + str(X[i]))</span><br><span class="line">print(<span class="string">"Prediction: "</span> + str(max_prediction))</span><br><span class="line">print(<span class="string">"Prediction text: "</span> + str(str_prediction))</span><br></pre></td></tr></table></figure>
<pre><code>Input: 13.09
Tokenized: [ 4  6  2  3 12 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
 40 40]
Prediction: [1, 3, 10, 0, 9]
Prediction text: 13:09
</code></pre><p>Last but not least, all introductions to Attention networks require a little tour.</p>
<p>The below graph shows what inputs the model was focusing on when writing each individual letter.</p>
<h2 id="注意力机制图"><a href="#注意力机制图" class="headerlink" title="注意力机制图"></a>注意力机制图</h2><p><img src="/2019/02/28/注意力机制/e1.png" alt=""></p>
<h1 id="注意力机制精要"><a href="#注意力机制精要" class="headerlink" title="注意力机制精要"></a>注意力机制精要</h1><p><img src="/2019/02/28/注意力机制/a1.png" alt=""><br><strong>全局注意力机制</strong></p>
<p><img src="/2019/02/28/注意力机制/a2.png" alt=""><br><strong>局部注意力机制</strong></p>
<p><img src="/2019/02/28/注意力机制/d1.jpg" alt=""><br><strong>自注意力机制</strong><br><img src="/2019/02/28/注意力机制/a3.png" alt=""></p>
<p>隐藏向量 $h_t$ 首先会传递到全连接层。然后校准系数 $a_t$ 会对比全连接层的输出 $u_t$ 和可训练上下文向量 u（随机初始化），并通过 Softmax 归一化而得出。注意力向量 s 最后可以为所有隐藏向量的加权和。上下文向量可以解释为在平均上表征的最优单词。但模型面临新的样本时，它会使用这一知识以决定哪一个词需要更加注意。在训练中，模型会通过反向传播更新上下文向量，即它会调整内部表征以确定最优词是什么。</p>
<blockquote>
<p>Self Attention与传统的Attention机制非常的不同：传统的Attention是基于source端和target端的隐变量（hidden state）计算Attention的，得到的结果是源端的每个词与目标端每个词之间的依赖关系。但Self Attention不同，它分别在source端和target端进行，仅与source input或者target input自身相关的Self Attention，捕捉source端或target端自身的词与词之间的依赖关系；然后再把source端的得到的self Attention加入到target端得到的Attention中，捕捉source端和target端词与词之间的依赖关系。因此，self Attention Attention比传统的Attention mechanism效果要好，主要原因之一是，传统的Attention机制忽略了源端或目标端句子中词与词之间的依赖关系，相对比，self Attention可以不仅可以得到源端与目标端词与词之间的依赖关系，同时还可以有效获取源端或目标端自身词与词之间的依赖关系</p>
</blockquote>
<p><img src="/2019/02/28/注意力机制/a4.png" alt=""><br><strong>层级注意力机制</strong></p>
<p>在该架构中，自注意力机制共使用了两次：在词层面与在句子层面。该方法因为两个原因而非常重要，首先是它匹配文档的自然层级结构（词——句子——文档）。其次在计算文档编码的过程中，它允许模型首先确定哪些单词在句子中是非常重要的，然后再确定哪个句子在文档中是非常重要的。</p>
<h1 id="可视化神经机器翻译模型"><a href="#可视化神经机器翻译模型" class="headerlink" title="可视化神经机器翻译模型"></a>可视化神经机器翻译模型</h1><p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a></p>

    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>本站所有文章和源码均免费开放，如您喜欢，可以请我喝杯咖啡</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="袁宵 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="袁宵 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>袁宵</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://yuanxiaosc.github.io/2019/02/28/注意力机制/" title="注意力机制">https://yuanxiaosc.github.io/2019/02/28/注意力机制/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/注意力机制/" rel="tag"># 注意力机制</a>
            
              <a href="/tags/Attention-Mechanism/" rel="tag"># Attention Mechanism</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/02/21/jupyter/" rel="next" title="jupyter">
                  <i class="fa fa-chevron-left"></i> jupyter
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/03/01/神经机器翻译/" rel="prev" title="神经机器翻译 | Neural Machine Translation">
                  神经机器翻译 | Neural Machine Translation <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#以2014《Learning-Phrase-Representations-using-RNN-Encoder-Decoder-for-Statistical-Machine-Translation》抛砖引玉"><span class="nav-number">1.</span> <span class="nav-text">以2014《Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation》抛砖引玉</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#以Attention-Network-With-Keras-为例讲解一种Attention实现代码"><span class="nav-number">2.</span> <span class="nav-text">以Attention_Network_With_Keras 为例讲解一种Attention实现代码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#部分代码"><span class="nav-number">2.1.</span> <span class="nav-text">部分代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model"><span class="nav-number">2.2.</span> <span class="nav-text">Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型结构及说明"><span class="nav-number">2.3.</span> <span class="nav-text">模型结构及说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型评估"><span class="nav-number">2.4.</span> <span class="nav-text">模型评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evaluation"><span class="nav-number">2.5.</span> <span class="nav-text">Evaluation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#注意力机制图"><span class="nav-number">2.6.</span> <span class="nav-text">注意力机制图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#注意力机制精要"><span class="nav-number">3.</span> <span class="nav-text">注意力机制精要</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#可视化神经机器翻译模型"><span class="nav-number">4.</span> <span class="nav-text">可视化神经机器翻译模型</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.png"
      alt="袁宵">
  <p class="site-author-name" itemprop="name">袁宵</p>
  <div class="site-description" itemprop="description">专注于机器学习前沿论文（技术）研究和应用，欢迎邮件交流。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives">
        
          <span class="site-state-item-count">144</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">127</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/yuanxiaoSC" title="GitHub &rarr; https://github.com/yuanxiaoSC" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:wangzichaochaochao@gmail.com" title="E-Mail &rarr; mailto:wangzichaochaochao@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>
  <div class="cc-license motion-element" itemprop="license">
    
  
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
	  

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">袁宵</span>
</div>
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5d9c4b1ac4deb418" async="async"></script>
  </div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">全站共 383k 字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="//cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-ribbon@1/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>








  <script src="/js/local-search.js?v=7.4.1"></script>





  <script src="//code.tidio.co/ohblyq9gicnjwqem8o1hfoymk3calgui.js"></script>









  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
